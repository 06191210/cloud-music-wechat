{"version":3,"sources":["index.js","FsPromise.js","core.js","ReadStreamTokenizer.js","AbstractTokenizer.js","BufferTokenizer.js","FileTokenizer.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ACHA,AFMA;ACFA,ACHA,AFMA;ACFA,ACHA,AFMA;ACFA,AENA,ADGA,AFMA;ACFA,AENA,ADGA,AFMA;ACFA,AENA,ADGA,AFMA;AIXA,AHSA,AENA,ADGA,AFMA;AIXA,AHSA,AENA,ADGA,AFMA;AIXA,AHSA,AENA,ADGA,AFMA;AIXA,ACHA,AJYA,AENA,ADGA,AFMA;AIXA,ACHA,AJYA,AENA,ADGA,AFMA;AIXA,ACHA,AJYA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA,AFMA;AIXA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA,ADGA;AELA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,ACHA,ACHA,ALeA,AENA;ACFA,AENA,ALeA,AENA;ACFA,AENA,ALeA,AENA;ACFA,AENA,ALeA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,AHSA,AENA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.fromStream = exports.fromBuffer = exports.EndOfStreamError = exports.fromFile = void 0;\r\nconst fs = require(\"./FsPromise\");\r\nconst core = require(\"./core\");\r\nvar FileTokenizer_1 = require(\"./FileTokenizer\");\r\nObject.defineProperty(exports, \"fromFile\", { enumerable: true, get: function () { return FileTokenizer_1.fromFile; } });\r\nvar core_1 = require(\"./core\");\r\nObject.defineProperty(exports, \"EndOfStreamError\", { enumerable: true, get: function () { return core_1.EndOfStreamError; } });\r\nObject.defineProperty(exports, \"fromBuffer\", { enumerable: true, get: function () { return core_1.fromBuffer; } });\r\n/**\r\n * Construct ReadStreamTokenizer from given Stream.\r\n * Will set fileSize, if provided given Stream has set the .path property.\r\n * @param stream - Node.js Stream.Readable\r\n * @param fileInfo - Pass additional file information to the tokenizer\r\n * @returns Tokenizer\r\n */\r\nasync function fromStream(stream, fileInfo) {\r\n    fileInfo = fileInfo ? fileInfo : {};\r\n    if (stream.path) {\r\n        const stat = await fs.stat(stream.path);\r\n        fileInfo.path = stream.path;\r\n        fileInfo.size = stat.size;\r\n    }\r\n    return core.fromStream(stream, fileInfo);\r\n}\r\nexports.fromStream = fromStream;\r\n","\r\n/**\r\n * Module convert fs functions to promise based functions\r\n */\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.readFile = exports.writeFileSync = exports.writeFile = exports.read = exports.open = exports.close = exports.stat = exports.createReadStream = exports.pathExists = void 0;\r\nconst fs = require(\"fs\");\r\nexports.pathExists = fs.existsSync;\r\nexports.createReadStream = fs.createReadStream;\r\nasync function stat(path) {\r\n    return new Promise((resolve, reject) => {\r\n        fs.stat(path, (err, stats) => {\r\n            if (err)\r\n                reject(err);\r\n            else\r\n                resolve(stats);\r\n        });\r\n    });\r\n}\r\nexports.stat = stat;\r\nasync function close(fd) {\r\n    return new Promise((resolve, reject) => {\r\n        fs.close(fd, err => {\r\n            if (err)\r\n                reject(err);\r\n            else\r\n                resolve();\r\n        });\r\n    });\r\n}\r\nexports.close = close;\r\nasync function open(path, mode) {\r\n    return new Promise((resolve, reject) => {\r\n        fs.open(path, mode, (err, fd) => {\r\n            if (err)\r\n                reject(err);\r\n            else\r\n                resolve(fd);\r\n        });\r\n    });\r\n}\r\nexports.open = open;\r\nasync function read(fd, buffer, offset, length, position) {\r\n    return new Promise((resolve, reject) => {\r\n        fs.read(fd, buffer, offset, length, position, (err, bytesRead, _buffer) => {\r\n            if (err)\r\n                reject(err);\r\n            else\r\n                resolve({ bytesRead, buffer: _buffer });\r\n        });\r\n    });\r\n}\r\nexports.read = read;\r\nasync function writeFile(path, data) {\r\n    return new Promise((resolve, reject) => {\r\n        fs.writeFile(path, data, err => {\r\n            if (err)\r\n                reject(err);\r\n            else\r\n                resolve();\r\n        });\r\n    });\r\n}\r\nexports.writeFile = writeFile;\r\nfunction writeFileSync(path, data) {\r\n    fs.writeFileSync(path, data);\r\n}\r\nexports.writeFileSync = writeFileSync;\r\nasync function readFile(path) {\r\n    return new Promise((resolve, reject) => {\r\n        fs.readFile(path, (err, buffer) => {\r\n            if (err)\r\n                reject(err);\r\n            else\r\n                resolve(buffer);\r\n        });\r\n    });\r\n}\r\nexports.readFile = readFile;\r\n","\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.fromBuffer = exports.fromStream = exports.EndOfStreamError = void 0;\r\nconst ReadStreamTokenizer_1 = require(\"./ReadStreamTokenizer\");\r\nconst BufferTokenizer_1 = require(\"./BufferTokenizer\");\r\nvar peek_readable_1 = require(\"peek-readable\");\r\nObject.defineProperty(exports, \"EndOfStreamError\", { enumerable: true, get: function () { return peek_readable_1.EndOfStreamError; } });\r\n/**\r\n * Construct ReadStreamTokenizer from given Stream.\r\n * Will set fileSize, if provided given Stream has set the .path property/\r\n * @param stream - Read from Node.js Stream.Readable\r\n * @param fileInfo - Pass the file information, like size and MIME-type of the corresponding stream.\r\n * @returns ReadStreamTokenizer\r\n */\r\nfunction fromStream(stream, fileInfo) {\r\n    fileInfo = fileInfo ? fileInfo : {};\r\n    return new ReadStreamTokenizer_1.ReadStreamTokenizer(stream, fileInfo);\r\n}\r\nexports.fromStream = fromStream;\r\n/**\r\n * Construct ReadStreamTokenizer from given Buffer.\r\n * @param uint8Array - Uint8Array to tokenize\r\n * @param fileInfo - Pass additional file information to the tokenizer\r\n * @returns BufferTokenizer\r\n */\r\nfunction fromBuffer(uint8Array, fileInfo) {\r\n    return new BufferTokenizer_1.BufferTokenizer(uint8Array, fileInfo);\r\n}\r\nexports.fromBuffer = fromBuffer;\r\n","\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.ReadStreamTokenizer = void 0;\r\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\r\nconst peek_readable_1 = require(\"peek-readable\");\r\nconst maxBufferSize = 256000;\r\nclass ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    constructor(stream, fileInfo) {\r\n        super(fileInfo);\r\n        this.streamReader = new peek_readable_1.StreamReader(stream);\r\n    }\r\n    /**\r\n     * Get file information, an HTTP-client may implement this doing a HEAD request\r\n     * @return Promise with file information\r\n     */\r\n    async getFileInfo() {\r\n        return this.fileInfo;\r\n    }\r\n    /**\r\n     * Read buffer from tokenizer\r\n     * @param uint8Array - Target Uint8Array to fill with data read from the tokenizer-stream\r\n     * @param options - Read behaviour options\r\n     * @returns Promise with number of bytes read\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const skipBytes = normOptions.position - this.position;\r\n        if (skipBytes > 0) {\r\n            await this.ignore(skipBytes);\r\n            return this.readBuffer(uint8Array, options);\r\n        }\r\n        else if (skipBytes < 0) {\r\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\r\n        }\r\n        if (normOptions.length === 0) {\r\n            return 0;\r\n        }\r\n        const bytesRead = await this.streamReader.read(uint8Array, normOptions.offset, normOptions.length);\r\n        this.position += bytesRead;\r\n        if ((!options || !options.mayBeLess) && bytesRead < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return bytesRead;\r\n    }\r\n    /**\r\n     * Peek (read ahead) buffer from tokenizer\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise with number of bytes peeked\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        let bytesRead = 0;\r\n        if (normOptions.position) {\r\n            const skipBytes = normOptions.position - this.position;\r\n            if (skipBytes > 0) {\r\n                const skipBuffer = new Uint8Array(normOptions.length + skipBytes);\r\n                bytesRead = await this.peekBuffer(skipBuffer, { mayBeLess: normOptions.mayBeLess });\r\n                uint8Array.set(skipBuffer.subarray(skipBytes), normOptions.offset);\r\n                return bytesRead - skipBytes;\r\n            }\r\n            else if (skipBytes < 0) {\r\n                throw new Error('Cannot peek from a negative offset in a stream');\r\n            }\r\n        }\r\n        if (normOptions.length > 0) {\r\n            try {\r\n                bytesRead = await this.streamReader.peek(uint8Array, normOptions.offset, normOptions.length);\r\n            }\r\n            catch (err) {\r\n                if (options && options.mayBeLess && err instanceof peek_readable_1.EndOfStreamError) {\r\n                    return 0;\r\n                }\r\n                throw err;\r\n            }\r\n            if ((!normOptions.mayBeLess) && bytesRead < normOptions.length) {\r\n                throw new peek_readable_1.EndOfStreamError();\r\n            }\r\n        }\r\n        return bytesRead;\r\n    }\r\n    async ignore(length) {\r\n        // debug(`ignore ${this.position}...${this.position + length - 1}`);\r\n        const bufSize = Math.min(maxBufferSize, length);\r\n        const buf = new Uint8Array(bufSize);\r\n        let totBytesRead = 0;\r\n        while (totBytesRead < length) {\r\n            const remaining = length - totBytesRead;\r\n            const bytesRead = await this.readBuffer(buf, { length: Math.min(bufSize, remaining) });\r\n            if (bytesRead < 0) {\r\n                return bytesRead;\r\n            }\r\n            totBytesRead += bytesRead;\r\n        }\r\n        return totBytesRead;\r\n    }\r\n}\r\nexports.ReadStreamTokenizer = ReadStreamTokenizer;\r\n","\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.AbstractTokenizer = void 0;\r\nconst peek_readable_1 = require(\"peek-readable\");\r\n/**\r\n * Core tokenizer\r\n */\r\nclass AbstractTokenizer {\r\n    constructor(fileInfo) {\r\n        /**\r\n         * Tokenizer-stream position\r\n         */\r\n        this.position = 0;\r\n        this.numBuffer = new Uint8Array(8);\r\n        this.fileInfo = fileInfo ? fileInfo : {};\r\n    }\r\n    /**\r\n     * Read a token from the tokenizer-stream\r\n     * @param token - The token to read\r\n     * @param position - If provided, the desired position in the tokenizer-stream\r\n     * @returns Promise with token data\r\n     */\r\n    async readToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.readBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Peek a token from the tokenizer-stream.\r\n     * @param token - Token to peek from the tokenizer-stream.\r\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n     * @returns Promise with token data\r\n     */\r\n    async peekToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.peekBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async readNumber(token) {\r\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async peekNumber(token) {\r\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n     * @param length - Number of bytes to ignore\r\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n     */\r\n    async ignore(length) {\r\n        if (this.fileInfo.size !== undefined) {\r\n            const bytesLeft = this.fileInfo.size - this.position;\r\n            if (length > bytesLeft) {\r\n                this.position += bytesLeft;\r\n                return bytesLeft;\r\n            }\r\n        }\r\n        this.position += length;\r\n        return length;\r\n    }\r\n    async close() {\r\n        // empty\r\n    }\r\n    normalizeOptions(uint8Array, options) {\r\n        if (options && options.position !== undefined && options.position < this.position) {\r\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\r\n        }\r\n        if (options) {\r\n            return {\r\n                mayBeLess: options.mayBeLess === true,\r\n                offset: options.offset ? options.offset : 0,\r\n                length: options.length ? options.length : (uint8Array.length - (options.offset ? options.offset : 0)),\r\n                position: options.position ? options.position : this.position\r\n            };\r\n        }\r\n        return {\r\n            mayBeLess: false,\r\n            offset: 0,\r\n            length: uint8Array.length,\r\n            position: this.position\r\n        };\r\n    }\r\n}\r\nexports.AbstractTokenizer = AbstractTokenizer;\r\n","\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.BufferTokenizer = void 0;\r\nconst peek_readable_1 = require(\"peek-readable\");\r\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\r\nclass BufferTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    /**\r\n     * Construct BufferTokenizer\r\n     * @param uint8Array - Uint8Array to tokenize\r\n     * @param fileInfo - Pass additional file information to the tokenizer\r\n     */\r\n    constructor(uint8Array, fileInfo) {\r\n        super(fileInfo);\r\n        this.uint8Array = uint8Array;\r\n        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : uint8Array.length;\r\n    }\r\n    /**\r\n     * Read buffer from tokenizer\r\n     * @param uint8Array - Uint8Array to tokenize\r\n     * @param options - Read behaviour options\r\n     * @returns {Promise<number>}\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        if (options && options.position) {\r\n            if (options.position < this.position) {\r\n                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\r\n            }\r\n            this.position = options.position;\r\n        }\r\n        const bytesRead = await this.peekBuffer(uint8Array, options);\r\n        this.position += bytesRead;\r\n        return bytesRead;\r\n    }\r\n    /**\r\n     * Peek (read ahead) buffer from tokenizer\r\n     * @param uint8Array\r\n     * @param options - Read behaviour options\r\n     * @returns {Promise<number>}\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const bytes2read = Math.min(this.uint8Array.length - normOptions.position, normOptions.length);\r\n        if ((!normOptions.mayBeLess) && bytes2read < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        else {\r\n            uint8Array.set(this.uint8Array.subarray(normOptions.position, normOptions.position + bytes2read), normOptions.offset);\r\n            return bytes2read;\r\n        }\r\n    }\r\n    async close() {\r\n        // empty\r\n    }\r\n}\r\nexports.BufferTokenizer = BufferTokenizer;\r\n","\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.fromFile = exports.FileTokenizer = void 0;\r\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\r\nconst peek_readable_1 = require(\"peek-readable\");\r\nconst fs = require(\"./FsPromise\");\r\nclass FileTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    constructor(fd, fileInfo) {\r\n        super(fileInfo);\r\n        this.fd = fd;\r\n    }\r\n    /**\r\n     * Read buffer from file\r\n     * @param uint8Array - Uint8Array to write result to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        this.position = normOptions.position;\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        this.position += res.bytesRead;\r\n        if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    /**\r\n     * Peek buffer from file\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        if ((!normOptions.mayBeLess) && res.bytesRead < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    async close() {\r\n        return fs.close(this.fd);\r\n    }\r\n}\r\nexports.FileTokenizer = FileTokenizer;\r\nasync function fromFile(sourceFilePath) {\r\n    const stat = await fs.stat(sourceFilePath);\r\n    if (!stat.isFile) {\r\n        throw new Error(`File not a file: ${sourceFilePath}`);\r\n    }\r\n    const fd = await fs.open(sourceFilePath, 'r');\r\n    return new FileTokenizer(fd, { path: sourceFilePath, size: stat.size });\r\n}\r\nexports.fromFile = fromFile;\r\n"]}